{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2381fb9e",
   "metadata": {},
   "source": [
    "# *The missing link:*\n",
    "# CAS Applied Data Science Final Project\n",
    "# Matthias Rinderknecht\n",
    "\n",
    "## Notebook 4: Searching for matches using the Faiss package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113f2ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded03b72",
   "metadata": {},
   "source": [
    "### Load the corpus to be encoded and precompute the index using Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d53509c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 502.74 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8714"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#works, loads the corpus to be encoded from .csv\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = SentenceTransformer(\"/Users/marinder/Documents/CAS_ADS/Final Project/Model_7/linkage\")\n",
    "\n",
    "# Load the corpus from a CSV file\n",
    "corpus_df = pd.read_csv('/Users/marinder/Documents/CAS_ADS/Final Project/Source Data/final_source/csv/ICTRP_only(CH=true)_12820x23.csv')\n",
    "\n",
    "# Specify the columns to be embedded for index search\n",
    "text_columns = [\"scientificTitle\", \"publicTitle\", \"interventions\", \"healthConditions\"]  # Replace with your actual column names\n",
    "\n",
    "# Concatenate the specified columns into a single text\n",
    "corpus = corpus_df[text_columns].apply(lambda row: ' '.join(row.values.astype(str)), axis=1).tolist()\n",
    "\n",
    "# Encode the corpus\n",
    "corpus_embeddings = model.encode(corpus)\n",
    "\n",
    "# Normalize the embeddings - to ensure that IP->cosine sim which is bounded to 1\n",
    "faiss.normalize_L2(corpus_embeddings)\n",
    "# Dimension of our vectors\n",
    "d = corpus_embeddings.shape[1]\n",
    "\n",
    "# Creating a FAISS index for inner product\n",
    "index = faiss.IndexFlatIP(d)  # Use IndexFlatIP to search with inner product\n",
    "\n",
    "# Adding normalized corpus embeddings to the index\n",
    "index.add(corpus_embeddings)\n",
    "\n",
    "# Save the index\n",
    "faiss.write_index(index, 'ICTRP_only_(CH=true)12820x23(sT,pT,int,hC).index')\n",
    "\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the execution time\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# Print the execution time\n",
    "print(f\"Execution time: {execution_time:.1f} seconds\")\n",
    "# Free up memory\n",
    "del corpus_df, corpus, corpus_embeddings, model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c534e5c",
   "metadata": {},
   "source": [
    "### Link a row from the corpus df to every search row using the precomputed index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ff611b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "MODEL = \"/Users/marinder/Documents/CAS_ADS/Final Project/Model_7/linkage\"\n",
    "INDEX = \"ICTRP_only_(CH=true)12820x23(sT,pT,int,hC).index\"\n",
    "CORPUS = \"/Users/marinder/Documents/CAS_ADS/Final Project/Source Data/final_source/csv/ICTRP_only(CH=true)_12820x23.csv\"\n",
    "SEARCH = \"/Users/marinder/Documents/CAS_ADS/Final Project/Source Data/final_source/csv/BASEC_without_ICTRP_1535x12.csv\"\n",
    "QUERY = [\"layTitle\", \"layTitle\", \"intervention\", \"disease\"]\n",
    "RESULT = '/Users/marinder/Documents/CAS_ADS/Final Project/Merges/FAISS/result_5.csv'\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = SentenceTransformer(MODEL)\n",
    "\n",
    "# Load the index (=precomputed corpus)\n",
    "index = faiss.read_index(INDEX)\n",
    "\n",
    "# Load the corpus from a CSV file\n",
    "corpus_df = pd.read_csv(CORPUS)\n",
    "\n",
    "# Load the new data to search for\n",
    "query_df = pd.read_csv(SEARCH)\n",
    "\n",
    "# Specify the columns to be embedded for querying\n",
    "query_columns = QUERY\n",
    "\n",
    "# Concatenate the specified columns into a single text for each row\n",
    "queries = query_df[query_columns].apply(lambda row: ' '.join(row.values.astype(str)), axis=1).tolist()\n",
    "\n",
    "# Encode the queries\n",
    "query_embeddings = model.encode(queries)\n",
    "\n",
    "# Normalize the query embeddings\n",
    "faiss.normalize_L2(query_embeddings)\n",
    "\n",
    "# Search for similar embeddings\n",
    "k = 1  # Retrieve the top match\n",
    "distances, indices = index.search(query_embeddings, k)\n",
    "\n",
    "#initialize counters\n",
    "correct_matches = 0\n",
    "total_rows = len(query_df)\n",
    "\n",
    "# Rename overlapping columns in new_row\n",
    "query_df.columns = [f\"new_{col}\" if col in corpus_df.columns else col for col in query_df.columns]\n",
    "\n",
    "# Rename overlapping columns in corpus_df\n",
    "corpus_df.columns = [f\"corpus_{col}\" if col in query_df.columns else col for col in corpus_df.columns]\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "result_df = pd.DataFrame(columns=list(query_df.columns) + list(corpus_df.columns) + ['score'])\n",
    "\n",
    "# Process the search results\n",
    "for i, row in query_df.iterrows():\n",
    "    query_embedding = query_embeddings[i]\n",
    "    query_distance, query_index = distances[i][0], indices[i][0]\n",
    "\n",
    "    # Create a new row by combining the query row and the matched corpus row\n",
    "    result_row_values = list(query_df.iloc[i]) + list(corpus_df.iloc[query_index]) + [query_distance]\n",
    "    result_row_df = pd.DataFrame([result_row_values], columns=result_df.columns)\n",
    "\n",
    "    # Append the result_row_df to result_df\n",
    "    result_df = pd.concat([result_df, result_row_df], ignore_index=True)\n",
    "    \n",
    "print(query_df.shape)\n",
    "print (result_df.shape)\n",
    "print (corpus_df.shape)\n",
    "\n",
    "#reorder columns\n",
    "new_column_order = [\n",
    "    \"score\",\n",
    "    \"snctpId\",\n",
    "    \"whoId\",\n",
    "    \"trialId\",\n",
    "    \"layTitle\",\n",
    "    \"scientificTitle\",\n",
    "    \"publicTitle\",\n",
    "    \"intervention\",\n",
    "    \"interventions\",\n",
    "    \"disease\",\n",
    "    \"healthConditions\",\n",
    "    \"laySummary\",\n",
    "    \"basecId\",\n",
    "    \"inclusionCriteria\",\n",
    "    \"exclusionCriteria\",\n",
    "    \"studysites\",\n",
    "    \"studySitesOther\",\n",
    "    \"tags\",\n",
    "    \"countries\",\n",
    "    \"secondaryId\",\n",
    "    \"primarySponsor\",\n",
    "    \"phase\",\n",
    "    \"primaryOutcome\",\n",
    "    \"publicContactAffiliation\",]\n",
    "\n",
    "result_df = result_df[new_column_order]\n",
    "\n",
    "# Save the result_df to a CSV file\n",
    "result_df.to_csv(RESULT, index=False)\n",
    "\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the execution time\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# Print the execution time\n",
    "print(f\"Execution time: {execution_time:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ff15eb",
   "metadata": {},
   "source": [
    "## Code for single matches (choosing one specific row in the query and matching the best row from the corpus to it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5dbea0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL = \"/Users/marinder/Documents/CAS_ADS/Final Project/Model_7/linkage\"\n",
    "INDEX = \"ICTRP_only_(CH=true)12820x23(sT,pT,int,hC).index\"\n",
    "CORPUS = \"/Users/marinder/Documents/CAS_ADS/Final Project/Source Data/final_source/csv/ICTRP_only(CH=true)_12820x23.csv\"\n",
    "SEARCH = \"/Users/marinder/Documents/CAS_ADS/Final Project/Source Data/final_source/csv/BASEC_without_ICTRP_1535x12.csv\"\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = SentenceTransformer(MODEL)\n",
    "\n",
    "# Load the index (=precomputed corpus)\n",
    "index = faiss.read_index(INDEX)\n",
    "\n",
    "# Load the corpus from a CSV file\n",
    "corpus_df = pd.read_csv(CORPUS)\n",
    "\n",
    "# Load the new data to search for\n",
    "query_df = pd.read_csv(SEARCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f93ffc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose row number to match (0-249): 999\n",
      "basecId                                                     2022-00157\n",
      "snctpId                                                 SNCTP000004998\n",
      "whoId                                                      NCT04790253\n",
      "layTitle             PRophylaktische Hirnbestrahlung oder aktive MA...\n",
      "laySummary           Patientinnen und Patienten mit kleinzelligem L...\n",
      "disease                                   kleinzelligem Lungenkarzinom\n",
      "intervention         Studienarm mit aktiver Überwachung:\\r\\nMRT des...\n",
      "inclusionCriteria     Alter >= 18 Jahre\\r\\n Histologisch/zytologi...\n",
      "exclusionCriteria    \\tVorherige Strahlentherapie des Gehirns oder...\n",
      "studysites                           Zürich, Bern, Lausanne, St Gallen\n",
      "studySitesOther                                                    NaN\n",
      "tags                                                       Lungenkrebs\n",
      "Name: 999, dtype: object\n",
      "Query_index: [153]\n",
      "WhoId: NCT04790253\n",
      "TrialId 153    NCT04790253\n",
      "Name: trialId, dtype: object\n",
      "Similarity: [0.8694606]\n",
      "153    PRophylactic Cerebral Irradiation or Active MA...\n",
      "Name: scientificTitle, dtype: object\n",
      "Execution time: 0.13 seconds\n"
     ]
    }
   ],
   "source": [
    "QUERY = [\"layTitle\", \"layTitle\", \"intervention\", \"disease\"]\n",
    "\n",
    "# Get the row number to match from user input\n",
    "matchrow = int(input(\"Choose row number to match (0-1535): \"))\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the row from the chosen row number\n",
    "one_row = query_df.iloc[matchrow]\n",
    "print(one_row)\n",
    "\n",
    "# Specify the columns to be embedded for querying\n",
    "query_columns = QUERY\n",
    "\n",
    "# Concatenate the specified columns into a single text for the selected row\n",
    "query_text = ' '.join(one_row[query_columns].astype(str))\n",
    "\n",
    "# Encode the query text\n",
    "query_embedding = model.encode([query_text])\n",
    "\n",
    "# Normalize the query embedding\n",
    "faiss.normalize_L2(query_embedding)\n",
    "\n",
    "# Search for similar embeddings\n",
    "k = 1  # Retrieve the top match\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "# Initialize counters\n",
    "correct_matches = 0\n",
    "total_rows = 1  # Since we're processing only one row\n",
    "\n",
    "# Process the search result\n",
    "query_distance, query_index = distances[0], indices[0]\n",
    "\n",
    "print(\"Query_index:\", query_index)\n",
    "\n",
    "# Check if the match is correct by comparing \"whoId\" from the query row with the corresponding corpus entry\n",
    "print(\"WhoId:\", one_row['whoId'])\n",
    "print(\"TrialId\", corpus_df.iloc[query_index]['trialId'])\n",
    "\n",
    "# Print the top match details\n",
    "print(\"Similarity:\", query_distance)\n",
    "print(corpus_df.iloc[query_index]['scientificTitle'])\n",
    "\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the execution time\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# Print the execution time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
